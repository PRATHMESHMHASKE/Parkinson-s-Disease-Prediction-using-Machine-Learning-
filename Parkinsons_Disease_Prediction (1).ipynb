{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "110c71fd",
   "metadata": {},
   "source": [
    "# Parkinson's Disease Prediction Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4324b102",
   "metadata": {},
   "source": [
    "Parkinsons Disease Prediction\n",
    "Install the following Libraries\n",
    "pip install pandas-profiling\n",
    "If Profiling is not working and getting an error use the following statement to install pandas profiling\n",
    "TypeError: concat() got an unexpected keyword argument 'join_axes' | Pandas Profiling\n",
    "pip install\n",
    "Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf521810",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a140de",
   "metadata": {},
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c4287c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119437cd",
   "metadata": {},
   "source": [
    "Check Current Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782513ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d65ebc7",
   "metadata": {},
   "source": [
    "Change the directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615227ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir ('C:\\\\Noble\\\\Training\\\\Acmegrade\\\\Data Science\\\\Projects\\\\Detection of Parkinsons Disease\\\\')\n",
    "print (os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89192c18",
   "metadata": {},
   "source": [
    "Read Data, display records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76210d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('parkinsons.data')\n",
    "display (df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db9ecd5",
   "metadata": {},
   "source": [
    "Attribute Information: Target column - Status\n",
    "Matrix column entries (attributes):\n",
    "name - ASCII subject name and recording number\n",
    "MDVP:Fo(Hz) - Average vocal fundamental frequency\n",
    "MDVP:Fhi(Hz) - Maximum vocal fundamental frequency\n",
    "MDVP:Flo(Hz) - Minimum vocal fundamental frequency\n",
    "MDVP:Jitter(%),MDVP:Jitter(Abs),MDVP:RAP,MDVP:PPQ,Jitter:DDP - Several\n",
    "measures of variation in fundamental frequency\n",
    "MDVP:Shimmer,MDVP:Shimmer(dB),Shimmer:APQ3,Shimmer:APQ5,MDVP:APQ,Shimmer:DDA - Several measures of variation in amplitude\n",
    "NHR,HNR - Two measures of ratio of noise to tonal components in the voice\n",
    "status - Health status of the subject (one) - Parkinson's, (zero) - healthy\n",
    "RPDE,D2 - Two nonlinear dynamical complexity measures\n",
    "DFA - Signal fractal scaling exponent\n",
    "spread1,spread2,PPE - Three nonlinear measures of fundamental frequency variation\n",
    "Pandas Profiling Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ad20db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ydata_profiling as pf\n",
    "display(pf.ProfileReport(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a40e1035",
   "metadata": {},
   "source": [
    "Display the shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f056f58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "display (df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5bc7677",
   "metadata": {},
   "source": [
    "Number of rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0673fee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f56c3c",
   "metadata": {},
   "source": [
    "Display the data type of all columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507ed981",
   "metadata": {},
   "outputs": [],
   "source": [
    "display (df.dtypes )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dff63d5",
   "metadata": {},
   "source": [
    "Display Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1376ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407b2684",
   "metadata": {},
   "source": [
    "Describe the details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099be2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "display (df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bdf7695",
   "metadata": {},
   "source": [
    "Check for Null Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5d7238",
   "metadata": {},
   "outputs": [],
   "source": [
    "display (df.isna().sum() )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf926e2",
   "metadata": {},
   "source": [
    "Display column details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217430bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e9555e",
   "metadata": {},
   "source": [
    "Display the dependent variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6765578",
   "metadata": {},
   "outputs": [],
   "source": [
    "# status - health status of the subject (one) - Parkinson's, (zero) – healthy\n",
    "print (df['status'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95715dbf",
   "metadata": {},
   "source": [
    "Create Histogram with Status column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df32fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The dataset has high number of patients effected with Parkinson's disease.\n",
    "plt.figure(figsize=(10, 6))\n",
    "df.status.hist()\n",
    "plt.xlabel('Status')\n",
    "plt.ylabel('Frequencies')\n",
    "plt.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c3afbd",
   "metadata": {},
   "source": [
    "Create Bar graph- X-Axis Status, Y- Axis NHR\n",
    "'''\n",
    "The patients affected with Parkinson's disease have high NHR which is the measure of the ratio of noise to tonal components in the voice.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da01e9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=\"status\",y=\"NHR\",data=df);\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d1abec",
   "metadata": {},
   "source": [
    "Create Bar graph- X-Axis Status, Y- Axis HNR\n",
    "'''\n",
    "The patients affected with Parkinson's disease have high HNR\n",
    "that is the measure of the ratio of noise to tonal components in the voice.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91fa3778",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=\"status\",y=\"HNR\",data=df);\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6882926",
   "metadata": {},
   "source": [
    "Create Bar graph- X-Axis Status, Y- Axis RPDE\n",
    "'''\n",
    "The nonlinear dynamical complexity measure RPDE is high in the patients affected with Parkinson's disease.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255fc747",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=\"status\",y=\"RPDE\",data=df);\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf86c824",
   "metadata": {},
   "source": [
    "Create Distribution plot – This used to check skewness in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40414b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "rows=3\n",
    "cols=7\n",
    "fig, ax=plt.subplots(nrows=rows,ncols=cols,figsize=(16,4))\n",
    "col=df.columns\n",
    "index=1\n",
    "for i in range(rows):\n",
    "for j in range(cols):\n",
    "sns.distplot(df[col[index]],ax=ax[i][j])\n",
    "index=index+1\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bcf3801",
   "metadata": {},
   "source": [
    "Display the top 3 records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36061220",
   "metadata": {},
   "outputs": [],
   "source": [
    "display (df.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb331660",
   "metadata": {},
   "source": [
    "Display Co relation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b84e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfc=df.iloc[:,1:]\n",
    "corr = dfc.corr()\n",
    "display (corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac367f2",
   "metadata": {},
   "source": [
    "Display Heat Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f52fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pylab import rcParams\n",
    "rcParams['figure.figsize'] = 20,10\n",
    "sns.heatmap(corr, xticklabels=corr.columns, yticklabels=corr.columns, cmap='cubehelix',annot = True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c576810",
   "metadata": {},
   "source": [
    "Heatmap with Default Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84d6e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pylab import rcParams\n",
    "rcParams['figure.figsize'] = 20,10\n",
    "sns.heatmap(corr)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496fd8a3",
   "metadata": {},
   "source": [
    "Drop the name column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961cd754",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing  name column for machine learning algorithms.\n",
    "df.drop(['name'],axis=1,inplace=True)\n",
    "display (df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b62bc54",
   "metadata": {},
   "source": [
    "Spitting the dataset into x and y\n",
    "Create X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8f0fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.drop(labels=['status'],axis=1)\n",
    "display (X.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0953daed",
   "metadata": {},
   "source": [
    "Create  – Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0dbe6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y=df['status']\n",
    "display (Y.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3520d9",
   "metadata": {},
   "source": [
    "Splitting the data into x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4325a8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.2,random_state=40)\n",
    "print (X.shape,Y.shape)\n",
    "print(X_train.shape,X_test.shape,Y_train.shape,Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c7cb05",
   "metadata": {},
   "source": [
    "Create a Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551f2b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression().fit(X_train, Y_train)\n",
    "#predict on train\n",
    "train_preds = log_reg.predict(X_train)\n",
    "#accuracy on train\n",
    "print(\"Model accuracy on train is: \", accuracy_score(Y_train, train_preds))\n",
    "#predict on test\n",
    "test_preds = log_reg.predict(X_test)\n",
    "#accuracy on test\n",
    "print(\"Model accuracy on test is: \", accuracy_score(Y_test, test_preds))\n",
    "print('-'*50)\n",
    "#Confusion matrix\n",
    "print(\"confusion_matrix train is:\\n \", confusion_matrix(Y_train, train_preds))\n",
    "print(\"confusion_matrix test is:\\n \", confusion_matrix(Y_test, test_preds))\n",
    "print('\\nClassification Report Train is ')\n",
    "print(classification_report (Y_train, train_preds))\n",
    "print('\\nClassification Report Test is ')\n",
    "print(classification_report (Y_test, test_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ebec9b7",
   "metadata": {},
   "source": [
    "Create Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e139ac28",
   "metadata": {},
   "outputs": [],
   "source": [
    "RF=RandomForestClassifier().fit(X_train,Y_train)\n",
    "#predict on train\n",
    "train_preds2 = RF.predict(X_train)\n",
    "#accuracy on train\n",
    "print(\"Model accuracy on train is: \", accuracy_score(Y_train, train_preds2))\n",
    "#predict on test\n",
    "test_preds2 = RF.predict(X_test)\n",
    "#accuracy on test\n",
    "print(\"Model accuracy on test is: \", accuracy_score(Y_test, test_preds2))\n",
    "#Confusion matrix\n",
    "print(\"confusion_matrix train is:\\n \", confusion_matrix(Y_train, train_preds2))\n",
    "print(\"confusion_matrix test is:\\n \", confusion_matrix(Y_test, test_preds2))\n",
    "print('\\nClassification Report Train is ')\n",
    "print(classification_report (Y_train, train_preds2))\n",
    "print('\\nClassification Report Test is ')\n",
    "print(classification_report (Y_test, test_preds2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d1801d",
   "metadata": {},
   "source": [
    "Wrong Predictions made"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6c76e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print((Y_test !=test_preds2).sum(),'/',((Y_test == test_preds2).sum()+(Y_test != test_preds2).sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b2b653",
   "metadata": {},
   "source": [
    "Kappa Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087c77db",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('KappaScore is: ', metrics.cohen_kappa_score(Y_test,test_preds2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13b6143",
   "metadata": {},
   "source": [
    "What is the meaning of kappa value?\n",
    "The higher the kappa value, the stronger the degree of agreement. When:\n",
    "Kappa = 1, perfect agreement exists. Kappa < 0, agreement is weaker than expected by chance; this rarely happens. Kappa close to 0, the degree of agreement is the same as would be expected by chance\n",
    "Display the test and Predicted Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5882272",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf=pd.DataFrame(data=[test_preds2,Y_test])\n",
    "display (ddf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "909727e7",
   "metadata": {},
   "source": [
    "Transpose and display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bfe9519",
   "metadata": {},
   "outputs": [],
   "source": [
    "display (ddf.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd122196",
   "metadata": {},
   "source": [
    "Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17cad9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "#fit the model on train data\n",
    "DT = DecisionTreeClassifier().fit(X,Y)\n",
    "#predict on train\n",
    "train_preds3 = DT.predict(X_train)\n",
    "#accuracy on train\n",
    "print(\"Model accuracy on train is: \", accuracy_score(Y_train, train_preds3))\n",
    "#predict on test\n",
    "test_preds3 = DT.predict(X_test)\n",
    "#accuracy on test\n",
    "print(\"Model accuracy on test is: \", accuracy_score(Y_test, test_preds3))\n",
    "print('-'*50)\n",
    "#Confusion matrix\n",
    "print(\"confusion_matrix train is:\\n \", confusion_matrix(Y_train, train_preds3))\n",
    "print(\"confusion_matrix test is: \\n\", confusion_matrix(Y_test, test_preds3))\n",
    "print('Wrong predictions out of total')\n",
    "print('-'*50)\n",
    "print('\\nClassification Report Train is ')\n",
    "print(classification_report (Y_train, train_preds3))\n",
    "print('\\nClassification Report Test is ')\n",
    "print(classification_report (Y_test, test_preds3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cbf87e1",
   "metadata": {},
   "source": [
    "Wrong Prediction and Kappa Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c877cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrong Predictions made.\n",
    "print((Y_test !=test_preds3).sum(),'/',((Y_test == test_preds3).sum()+(Y_test != test_preds3).sum()))\n",
    "print('-'*50)\n",
    "# Kappa Score\n",
    "print('KappaScore is: ', metrics.cohen_kappa_score(Y_test,test_preds3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1713ce00",
   "metadata": {},
   "source": [
    "Naïve Bayce  algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b77d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "#fit the model on train data\n",
    "NB=GaussianNB()\n",
    "NB.fit(X_train,Y_train)\n",
    "#predict on train\n",
    "train_preds4 = NB.predict(X_train)\n",
    "#accuracy on train\n",
    "print(\"Model accuracy on train is: \", accuracy_score(Y_train, train_preds4))\n",
    "#predict on test\n",
    "test_preds4 = NB.predict(X_test)\n",
    "#accuracy on test\n",
    "print(\"Model accuracy on test is: \", accuracy_score(Y_test, test_preds4))\n",
    "print('-'*50)\n",
    "#Confusion matrix\n",
    "print(\"confusion_matrix train is: \\n\", confusion_matrix(Y_train, train_preds4))\n",
    "print(\"confusion_matrix test is:\\n \", confusion_matrix(Y_test, test_preds4))\n",
    "print('Wrong predictions out of total')\n",
    "print('-'*50)\n",
    "print('\\nClassification Report Train is ')\n",
    "print(classification_report (Y_train, train_preds4))\n",
    "print('\\nClassification Report Test is ')\n",
    "print(classification_report (Y_test, test_preds4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a555b06b",
   "metadata": {},
   "source": [
    "Wrong Prediction and Kappa Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1d50bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrong Predictions made.\n",
    "print((Y_test !=test_preds4).sum(),'/',((Y_test == test_preds4).sum()+(Y_test != test_preds4).sum()))\n",
    "print('-'*50)\n",
    "# Kappa Score\n",
    "print('KappaScore is: ', metrics.cohen_kappa_score(Y_test,test_preds4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78948a66",
   "metadata": {},
   "source": [
    "K Neighbours Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae710d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "#fit the model on train data\n",
    "# Using the parameter weights='distance'  to fix the error 'Flags' object has no attribute 'c_contiguous'\n",
    "KNN = KNeighborsClassifier(weights='distance').fit(X_train,Y_train)\n",
    "#predict on train\n",
    "train_preds5 = KNN.predict(X_train)\n",
    "#accuracy on train\n",
    "print(\"Model accuracy on train is: \", accuracy_score(Y_train, train_preds5))\n",
    "#predict on test\n",
    "test_preds5 = KNN.predict(X_test)\n",
    "#accuracy on test\n",
    "print(\"Model accuracy on test is: \", accuracy_score(Y_test, test_preds5))\n",
    "print('-'*50)\n",
    "#Confusion matrix\n",
    "print(\"confusion_matrix train is:\\n \", confusion_matrix(Y_train, train_preds5))\n",
    "print(\"confusion_matrix test is:\\n \", confusion_matrix(Y_test, test_preds5))\n",
    "print('Wrong predictions out of total')\n",
    "print('-'*50)\n",
    "print('\\nClassification Report Train is ')\n",
    "print(classification_report (Y_train, train_preds5))\n",
    "print('\\nClassification Report Test is ')\n",
    "print(classification_report (Y_test, test_preds5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5c5531",
   "metadata": {},
   "source": [
    "Wrong Prediction and Kappa Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fabd19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrong Predictions made.\n",
    "print((Y_test !=test_preds5).sum(),'/',((Y_test == test_preds5).sum()+(Y_test != test_preds5).sum()))\n",
    "print('-'*50)\n",
    "# Kappa Score\n",
    "print('KappaScore is: ', metrics.cohen_kappa_score(Y_test,test_preds5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b1b3bd",
   "metadata": {},
   "source": [
    "Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d72742a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "#fit the model on train data\n",
    "SVM = SVC(kernel='linear')\n",
    "SVM.fit(X_train, Y_train)\n",
    "#predict on train\n",
    "train_preds6 = SVM.predict(X_train)\n",
    "#accuracy on train\n",
    "print(\"Model accuracy on train is: \", accuracy_score(Y_train, train_preds6))\n",
    "#predict on test\n",
    "test_preds6 = SVM.predict(X_test)\n",
    "#accuracy on test\n",
    "print(\"Model accuracy on test is: \", accuracy_score(Y_test, test_preds6))\n",
    "print('-'*50)\n",
    "#Confusion matrix\n",
    "print(\"confusion_matrix train is: \\n\", confusion_matrix(Y_train, train_preds6))\n",
    "print(\"confusion_matrix test is:\\n \", confusion_matrix(Y_test, test_preds6))\n",
    "print('Wrong predictions out of total')\n",
    "print('-'*50)\n",
    "print(\"recall\", metrics.recall_score(Y_test, test_preds6))\n",
    "print('-'*50)\n",
    "print('\\nClassification Report Train is ')\n",
    "print(classification_report (Y_train, train_preds6))\n",
    "print('\\nClassification Report Test is ')\n",
    "print(classification_report (Y_test, test_preds6))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75e962b",
   "metadata": {},
   "source": [
    "Wrong Prediction and Kappa Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf47f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrong Predictions made.\n",
    "print((Y_test !=test_preds6).sum(),'/',((Y_test == test_preds6).sum()+(Y_test != test_preds6).sum()))\n",
    "print('-'*50)\n",
    "# Kappa Score\n",
    "print('KappaScore is: ', metrics.cohen_kappa_score(Y_test,test_preds6))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0291b78b",
   "metadata": {},
   "source": [
    "Create Pickle File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d24f8dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# Saving model to disk\n",
    "pickle.dump(SVM,open('deploy_SVM.pkl','wb'))\n",
    "# Open the Pickle File\n",
    "model=pickle.load(open('deploy_SVM.pkl','rb'))\n",
    "# Prediction\n",
    "print (model.predict (X_train))"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
